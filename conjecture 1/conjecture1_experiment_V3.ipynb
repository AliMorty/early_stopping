{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjecture 1: Direction of GD Iterates (V3)\n",
    "\n",
    "Clean version with all functionality inside the class.\n",
    "- Resumable `run_gd(T)`: call once to run to T, call again with larger T to continue\n",
    "- All plotting via method calls: `plot_dashboard()`, `plot_trajectory()`, `print_summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OverparameterizedLogisticRegression:\n",
    "    \"\"\"\n",
    "    Data generator and GD runner for overparameterized logistic regression\n",
    "    following Assumption 1 from Wu et al. (2025).\n",
    "\n",
    "    Data model:\n",
    "        x ~ N(0, Sigma),  Pr(y|x) = 1 / (1 + exp(-y * x^T w*))\n",
    "\n",
    "    Covariance Sigma = U diag(lambda_1, ..., lambda_d) U^T where U = I\n",
    "    (we work directly in the eigenbasis).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d=2000, n=1000, k=100, eta=None, seed=42):\n",
    "        self.d = d\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.seed = seed\n",
    "\n",
    "        # Eigenvalues: lambda_i = i^{-2}\n",
    "        self.eigenvalues = np.array([(i + 1) ** (-2) for i in range(d)])\n",
    "\n",
    "        # True parameter in eigenbasis: first k components = 1, rest = 0\n",
    "        self.w_star = np.zeros(d)\n",
    "        self.w_star[:k] = 1.0\n",
    "\n",
    "        # Step size: eta <= 1 / (C0 * (1 + tr(Sigma) + lambda_1 * ln(1/delta) / n))\n",
    "        tr_sigma = np.sum(self.eigenvalues)\n",
    "        lambda_1 = self.eigenvalues[0]\n",
    "        delta = 0.01\n",
    "        C0 = 2.0\n",
    "        eta_upper = 1.0 / (C0 * (1 + tr_sigma + lambda_1 * np.log(1.0 / delta) / n))\n",
    "\n",
    "        if eta is None:\n",
    "            self.eta = eta_upper\n",
    "        else:\n",
    "            self.eta = min(eta, eta_upper)\n",
    "\n",
    "        print(f'Parameters: d={d}, n={n}, k={k}')\n",
    "        print(f'tr(Sigma) = {tr_sigma:.4f}')\n",
    "        print(f'eta (used) = {self.eta:.6f}')\n",
    "\n",
    "        # State\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.w_current = None  # current GD iterate\n",
    "        self.t_current = 0    # current GD step\n",
    "        self.w_history = []   # list of (t, w_t)\n",
    "        self.loss_history = [] # list of (t, loss)\n",
    "        self.w_tilde = None\n",
    "\n",
    "    def generate_data(self):\n",
    "        \"\"\"Generate n data points from the logistic model.\"\"\"\n",
    "        rng = np.random.RandomState(self.seed)\n",
    "        Z = rng.randn(self.n, self.d)\n",
    "        self.X = Z * np.sqrt(self.eigenvalues)[np.newaxis, :]\n",
    "\n",
    "        logits = self.X @ self.w_star\n",
    "        probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "        self.y = 2.0 * (rng.rand(self.n) < probs).astype(float) - 1.0\n",
    "\n",
    "        print(f'Data generated: X shape = {self.X.shape}, y shape = {self.y.shape}')\n",
    "        print(f'Label balance: {np.mean(self.y == 1):.2%} positive')\n",
    "\n",
    "    # ---- Loss functions ----\n",
    "\n",
    "    def empirical_logistic_loss(self, w):\n",
    "        \"\"\"Empirical logistic risk: (1/n) sum ln(1 + exp(-y_i x_i^T w)).\"\"\"\n",
    "        margins = self.y * (self.X @ w)\n",
    "        return np.mean(np.logaddexp(0, -margins))\n",
    "\n",
    "    def population_logistic_loss(self, w, n_samples=100000, seed=999):\n",
    "        \"\"\"Population logistic risk approximated via Monte Carlo.\"\"\"\n",
    "        rng = np.random.RandomState(seed)\n",
    "        Z = rng.randn(n_samples, self.d)\n",
    "        X_pop = Z * np.sqrt(self.eigenvalues)[np.newaxis, :]\n",
    "        logits = X_pop @ self.w_star\n",
    "        probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "        y_pop = 2.0 * (rng.rand(n_samples) < probs).astype(float) - 1.0\n",
    "        margins = y_pop * (X_pop @ w)\n",
    "        return np.mean(np.logaddexp(0, -margins))\n",
    "\n",
    "    def logistic_gradient(self, w):\n",
    "        \"\"\"Gradient of the empirical logistic risk.\"\"\"\n",
    "        margins = self.y * (self.X @ w)\n",
    "        sigmoid_neg = -1.0 / (1.0 + np.exp(margins))\n",
    "        return (self.X.T @ (sigmoid_neg * self.y)) / self.n\n",
    "\n",
    "    # ---- Gradient descent (resumable) ----\n",
    "\n",
    "    def run_gd(self, T, log_every=2000):\n",
    "        \"\"\"Run (or continue) gradient descent up to step T.\n",
    "\n",
    "        If already at step t_current, only computes steps t_current+1 to T.\n",
    "        Checkpoints are log-spaced + linearly spaced for plotting.\n",
    "        \"\"\"\n",
    "        if T <= self.t_current:\n",
    "            print(f'Already at t={self.t_current}, nothing to do.')\n",
    "            return\n",
    "\n",
    "        # Initialize w if first run\n",
    "        if self.w_current is None:\n",
    "            self.w_current = np.zeros(self.d)\n",
    "            loss = self.empirical_logistic_loss(self.w_current)\n",
    "            self.w_history.append((0, self.w_current.copy()))\n",
    "            self.loss_history.append((0, loss))\n",
    "            print(f'  t={0:>8d}: loss={loss:.6f}, ||w||={0:.4f}')\n",
    "\n",
    "        # Build checkpoints for the NEW range only\n",
    "        log_points = set(np.unique(np.logspace(\n",
    "            np.log10(max(1, self.t_current + 1)), np.log10(T), 200\n",
    "        ).astype(int)))\n",
    "        lin_points = set(range(\n",
    "            self.t_current + log_every - (self.t_current % log_every),\n",
    "            T + 1, log_every\n",
    "        ))\n",
    "        checkpoints_set = log_points | lin_points | {T}\n",
    "\n",
    "        print(f'Continuing GD from t={self.t_current} to t={T}...')\n",
    "        w = self.w_current.copy()\n",
    "\n",
    "        for t in range(self.t_current + 1, T + 1):\n",
    "            grad = self.logistic_gradient(w)\n",
    "            w = w - self.eta * grad\n",
    "\n",
    "            if t in checkpoints_set:\n",
    "                loss = self.empirical_logistic_loss(w)\n",
    "                self.w_history.append((t, w.copy()))\n",
    "                self.loss_history.append((t, loss))\n",
    "\n",
    "                if t % log_every == 0 or t == T:\n",
    "                    print(f'  t={t:>8d}: loss={loss:.6f}, ||w||={norm(w):.4f}')\n",
    "\n",
    "        self.w_current = w.copy()\n",
    "        self.t_current = T\n",
    "        print(f'Done. Total checkpoints: {len(self.w_history)}')\n",
    "\n",
    "    # ---- Max-margin direction ----\n",
    "\n",
    "    def compute_max_margin_direction(self):\n",
    "        \"\"\"Compute the max l2-margin direction w_tilde via dual SVM.\"\"\"\n",
    "        G = self.X @ self.X.T\n",
    "        YGY = np.outer(self.y, self.y) * G\n",
    "        n = self.n\n",
    "\n",
    "        def dual_objective(alpha):\n",
    "            return 0.5 * alpha @ YGY @ alpha - np.sum(alpha)\n",
    "\n",
    "        def dual_gradient(alpha):\n",
    "            return YGY @ alpha - np.ones(n)\n",
    "\n",
    "        alpha0 = np.ones(n) * 0.001\n",
    "        bounds = [(0, None)] * n\n",
    "        result = minimize(dual_objective, alpha0, jac=dual_gradient,\n",
    "                          method='L-BFGS-B', bounds=bounds,\n",
    "                          options={'maxiter': 5000, 'ftol': 1e-15, 'gtol': 1e-12})\n",
    "\n",
    "        alpha_star = result.x\n",
    "        w_svm = self.X.T @ (alpha_star * self.y)\n",
    "        self.w_tilde = w_svm / norm(w_svm)\n",
    "\n",
    "        margins = self.y * (self.X @ w_svm)\n",
    "        print(f'Max-margin SVM solved. Min margin = {np.min(margins):.6f}')\n",
    "        print(f'Support vectors (alpha > 1e-6): {np.sum(alpha_star > 1e-6)}')\n",
    "        return self.w_tilde\n",
    "\n",
    "    # ---- Plotting methods ----\n",
    "\n",
    "    def _compute_direction_stats(self):\n",
    "        \"\"\"Compute cosine similarities, norms from w_history.\"\"\"\n",
    "        w_star_dir = self.w_star / norm(self.w_star)\n",
    "        times, cos_wstar, cos_wtilde, norms = [], [], [], []\n",
    "\n",
    "        for t, w in self.w_history:\n",
    "            if t == 0:\n",
    "                continue\n",
    "            w_dir = w / norm(w)\n",
    "            times.append(t)\n",
    "            cos_wstar.append(np.dot(w_dir, w_star_dir))\n",
    "            if self.w_tilde is not None:\n",
    "                cos_wtilde.append(np.dot(w_dir, self.w_tilde))\n",
    "            norms.append(norm(w))\n",
    "\n",
    "        return (np.array(times), np.array(cos_wstar),\n",
    "                np.array(cos_wtilde) if self.w_tilde is not None else None,\n",
    "                np.array(norms))\n",
    "\n",
    "    def plot_dashboard(self, save_path=None):\n",
    "        \"\"\"Plot 2x2 dashboard: cosine similarities, norms, loss, angles.\"\"\"\n",
    "        times, cos_wstar, cos_wtilde, norms = self._compute_direction_stats()\n",
    "        w_star_dir = self.w_star / norm(self.w_star)\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "        # Plot 1: Cosine similarity\n",
    "        ax = axes[0, 0]\n",
    "        ax.semilogx(times, cos_wstar,\n",
    "                    label=r'$\\cos(w_t/\\|w_t\\|,\\; w^*/\\|w^*\\|)$', linewidth=2)\n",
    "        if cos_wtilde is not None:\n",
    "            ax.semilogx(times, cos_wtilde,\n",
    "                        label=r'$\\cos(w_t/\\|w_t\\|,\\; \\tilde{w})$', linewidth=2)\n",
    "            cos_star_tilde = np.dot(w_star_dir, self.w_tilde)\n",
    "            ax.axhline(cos_star_tilde, color='gray', linestyle='--', alpha=0.7,\n",
    "                       label=f'cos(w*, w_tilde) = {cos_star_tilde:.4f}')\n",
    "        ax.set_xlabel('GD iteration t (log scale)')\n",
    "        ax.set_ylabel('Cosine similarity')\n",
    "        ax.set_title('Direction of GD iterates over time')\n",
    "        ax.legend(fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # Plot 2: Norm\n",
    "        ax = axes[0, 1]\n",
    "        ax.semilogx(times, norms, linewidth=2, color='green')\n",
    "        ax.set_xlabel('GD iteration t (log scale)')\n",
    "        ax.set_ylabel(r'$\\|w_t\\|$')\n",
    "        ax.set_title('Norm of GD iterates over time')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # Plot 3: Empirical loss\n",
    "        ax = axes[1, 0]\n",
    "        loss_t = [t for t, l in self.loss_history if t > 0]\n",
    "        loss_v = [l for t, l in self.loss_history if t > 0]\n",
    "        ax.semilogx(loss_t, loss_v, linewidth=2, color='red')\n",
    "        ax.set_xlabel('GD iteration t (log scale)')\n",
    "        ax.set_ylabel('Empirical logistic loss')\n",
    "        ax.set_title('Empirical training loss over time')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # Plot 4: Angles\n",
    "        ax = axes[1, 1]\n",
    "        angle_wstar = np.degrees(np.arccos(np.clip(cos_wstar, -1, 1)))\n",
    "        ax.semilogx(times, angle_wstar,\n",
    "                    label=r'Angle to $w^*/\\|w^*\\|$', linewidth=2)\n",
    "        if cos_wtilde is not None:\n",
    "            angle_wtilde = np.degrees(np.arccos(np.clip(cos_wtilde, -1, 1)))\n",
    "            ax.semilogx(times, angle_wtilde,\n",
    "                        label=r'Angle to $\\tilde{w}$', linewidth=2)\n",
    "        ax.set_xlabel('GD iteration t (log scale)')\n",
    "        ax.set_ylabel('Angle (degrees)')\n",
    "        ax.set_title('Angular distance from GD direction to targets')\n",
    "        ax.legend(fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_trajectory(self, save_path=None):\n",
    "        \"\"\"Plot 2D trajectory of w_t/||w_t|| projected onto (w*, w_tilde) plane.\"\"\"\n",
    "        if self.w_tilde is None:\n",
    "            print('Run compute_max_margin_direction() first.')\n",
    "            return\n",
    "\n",
    "        w_star_dir = self.w_star / norm(self.w_star)\n",
    "\n",
    "        # Gram-Schmidt orthonormal basis for the (w*, w_tilde) plane\n",
    "        e1 = w_star_dir.copy()\n",
    "        e2 = self.w_tilde - np.dot(self.w_tilde, e1) * e1\n",
    "        e2 = e2 / norm(e2)\n",
    "\n",
    "        proj_wstar = np.array([np.dot(w_star_dir, e1), np.dot(w_star_dir, e2)])\n",
    "        proj_wtilde = np.array([np.dot(self.w_tilde, e1), np.dot(self.w_tilde, e2)])\n",
    "\n",
    "        proj_traj, traj_times = [], []\n",
    "        for t, w in self.w_history:\n",
    "            if t == 0:\n",
    "                continue\n",
    "            w_dir = w / norm(w)\n",
    "            proj_traj.append([np.dot(w_dir, e1), np.dot(w_dir, e2)])\n",
    "            traj_times.append(t)\n",
    "\n",
    "        proj_traj = np.array(proj_traj)\n",
    "        traj_times = np.array(traj_times)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        scatter = ax.scatter(proj_traj[:, 0], proj_traj[:, 1],\n",
    "                             c=np.log10(traj_times), cmap='viridis', s=15, zorder=2)\n",
    "        ax.plot(proj_traj[:, 0], proj_traj[:, 1],\n",
    "                color='gray', alpha=0.3, linewidth=0.5, zorder=1)\n",
    "\n",
    "        ax.scatter(*proj_wstar, color='red', s=200, marker='*',\n",
    "                   zorder=5, label=r'$w^*/\\|w^*\\|$')\n",
    "        ax.scatter(*proj_wtilde, color='blue', s=200, marker='D',\n",
    "                   zorder=5, label=r'$\\tilde{w}$ (max margin)')\n",
    "        ax.scatter(proj_traj[0, 0], proj_traj[0, 1], color='green', s=100,\n",
    "                   marker='o', zorder=5, label=f't={traj_times[0]} (start)')\n",
    "        ax.scatter(proj_traj[-1, 0], proj_traj[-1, 1], color='black', s=100,\n",
    "                   marker='s', zorder=5, label=f't={traj_times[-1]} (end)')\n",
    "\n",
    "        cbar = plt.colorbar(scatter, ax=ax)\n",
    "        cbar.set_label('log10(t)')\n",
    "        ax.set_xlabel(r'Projection onto $w^*/\\|w^*\\|$ direction')\n",
    "        ax.set_ylabel(r'Projection onto orthogonal direction')\n",
    "        ax.set_title(r'Trajectory of $w_t/\\|w_t\\|$ projected onto $(w^*, \\tilde{w})$ plane')\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "    def print_summary(self, key_times=None):\n",
    "        \"\"\"Print summary table at key time points.\"\"\"\n",
    "        w_star_dir = self.w_star / norm(self.w_star)\n",
    "\n",
    "        if key_times is None:\n",
    "            # Auto-select: powers of 10 and midpoints up to t_current\n",
    "            key_times = sorted(set(\n",
    "                [1, 10, 50, 100, 500, 1000, 2000, 5000] +\n",
    "                [10**i for i in range(1, int(np.log10(max(1, self.t_current))) + 1)] +\n",
    "                [self.t_current]\n",
    "            ))\n",
    "            key_times = [t for t in key_times if t <= self.t_current]\n",
    "\n",
    "        has_wtilde = self.w_tilde is not None\n",
    "        header = f\"{'t':>10s} | {'cos(w_t, w*)':>14s}\"\n",
    "        if has_wtilde:\n",
    "            header += f\" | {'cos(w_t, w_tilde)':>18s}\"\n",
    "        header += f\" | {'||w_t||':>10s} | {'emp. loss':>10s}\"\n",
    "        print(header)\n",
    "        print('-' * len(header))\n",
    "\n",
    "        for t, w in self.w_history:\n",
    "            if t in key_times and t > 0:\n",
    "                w_dir = w / norm(w)\n",
    "                cs = np.dot(w_dir, w_star_dir)\n",
    "                wn = norm(w)\n",
    "                loss = self.empirical_logistic_loss(w)\n",
    "                row = f'{t:>10d} | {cs:>14.6f}'\n",
    "                if has_wtilde:\n",
    "                    ct = np.dot(w_dir, self.w_tilde)\n",
    "                    row += f' | {ct:>18.6f}'\n",
    "                row += f' | {wn:>10.4f} | {loss:>10.6f}'\n",
    "                print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OverparameterizedLogisticRegression(d=2000, n=1000, k=100, seed=42)\n",
    "model.generate_data()\n",
    "model.compute_max_margin_direction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run_gd(T=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_dashboard()\n",
    "model.plot_trajectory()\n",
    "model.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue to longer horizon\n",
    "\n",
    "Just change T below and run these two cells to extend the trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run_gd(T=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_dashboard()\n",
    "model.plot_trajectory()\n",
    "model.print_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
